package persistence

import (
	"context"

	"github.com/jackc/pgx/v5/pgxpool"
	"github.com/spounge-ai/polykey/internal/domain"
)

type AuditRepository struct {
	db *pgxpool.Pool
}

func NewAuditRepository(db *pgxpool.Pool) (*AuditRepository, error) {
	return &AuditRepository{db: db}, nil
}

func (r *AuditRepository) CreateAuditEvent(ctx context.Context, event *domain.AuditEvent) error {
	query := `INSERT INTO audit_events (id, client_identity, operation, key_id, auth_decision_id, success, error_message, timestamp) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`
	_, err := r.db.Exec(ctx, query, event.ID, event.ClientIdentity, event.Operation, event.KeyID, event.AuthDecisionID, event.Success, event.Error, event.Timestamp)
	return err
}

func (r *AuditRepository) GetAuditHistory(ctx context.Context, keyID string, limit int) ([]*domain.AuditEvent, error) {
	query := `SELECT id, client_identity, operation, key_id, auth_decision_id, success, error_message, timestamp FROM audit_events WHERE key_id = $1 ORDER BY timestamp DESC LIMIT $2`
	rows, err := r.db.Query(ctx, query, keyID, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var events []*domain.AuditEvent
	for rows.Next() {
		var event domain.AuditEvent
		err := rows.Scan(&event.ID, &event.ClientIdentity, &event.Operation, &event.KeyID, &event.AuthDecisionID, &event.Success, &event.Error, &event.Timestamp)
		if err != nil {
			return nil, err
		}
		events = append(events, &event)
	}

	return events, nil
}
package persistence

import (
	"context"
	"log/slog"
	"strconv"
	"sync"
	"time"

	"github.com/spounge-ai/polykey/internal/domain"
	"github.com/spounge-ai/polykey/pkg/cache"
	pk "github.com/spounge-ai/spounge-proto/gen/go/polykey/v2"
)

const (
	// Cache configuration
	defaultCacheTTL     = 5 * time.Minute
	cacheCleanupInterval = 10 * time.Minute
)

// CachedRepository is a decorator for a KeyRepository that adds a caching layer.
type CachedRepository struct {
	repo          domain.KeyRepository
	cache         cache.Store[string, *domain.Key]
	cacheIndex    map[string]map[string]struct{}
	cacheIndexMux sync.RWMutex
	optimizer     *QueryOptimizer
	logger        *slog.Logger
}

// NewCachedRepository creates a new CachedRepository.
func NewCachedRepository(repo domain.KeyRepository, logger *slog.Logger) *CachedRepository {
	cr := &CachedRepository{
		repo:       repo,
		cacheIndex: make(map[string]map[string]struct{}),
		optimizer:  NewQueryOptimizer(),
		logger:     logger,
	}

	c := cache.New[string, *domain.Key](
		cache.WithDefaultTTL[string, *domain.Key](defaultCacheTTL),
		cache.WithCleanupInterval[string, *domain.Key](cacheCleanupInterval),
		cache.WithEvictionCallback[string, *domain.Key](cr.onCacheEvict),
	)
	cr.cache = c

	return cr
}

func (cr *CachedRepository) onCacheEvict(cacheKey string, key *domain.Key) {
	if key == nil {
		return
	}

	cr.cacheIndexMux.Lock()
	keyIDStr := key.ID.String()
	if keys, ok := cr.cacheIndex[keyIDStr]; ok {
		delete(keys, cacheKey)
		if len(keys) == 0 {
			delete(cr.cacheIndex, keyIDStr)
		}
	}
	cr.cacheIndexMux.Unlock()
}

func (cr *CachedRepository) GetKey(ctx context.Context, id domain.KeyID) (*domain.Key, error) {
	cacheKey := cr.getCacheKey(id, 0)
	if key, found := cr.cache.Get(ctx, cacheKey); found {
		return key, nil
	}

	key, err := cr.repo.GetKey(ctx, id)
	if err != nil {
		return nil, err
	}

	cr.storeInCache(cacheKey, key)
	return key, nil
}

func (cr *CachedRepository) GetKeyByVersion(ctx context.Context, id domain.KeyID, version int32) (*domain.Key, error) {
	cacheKey := cr.getCacheKey(id, version)
	if key, found := cr.cache.Get(ctx, cacheKey); found {
		return key, nil
	}

	key, err := cr.repo.GetKeyByVersion(ctx, id, version)
	if err != nil {
		return nil, err
	}

	cr.storeInCache(cacheKey, key)
	return key, nil
}

func (cr *CachedRepository) CreateKey(ctx context.Context, key *domain.Key) error {
	err := cr.repo.CreateKey(ctx, key)
	if err == nil {
		cr.invalidateCache(key.ID)
	}
	return err
}

func (cr *CachedRepository) CreateKeys(ctx context.Context, keys []*domain.Key) error {
	err := cr.repo.CreateKeys(ctx, keys)
	if err == nil {
		for _, key := range keys {
			cr.invalidateCache(key.ID)
		}
	}
	return err
}

func (cr *CachedRepository) ListKeys(ctx context.Context) ([]*domain.Key, error) {
	// Caching for ListKeys is complex and often not beneficial without proper invalidation strategies.
	// For now, we bypass the cache for this operation.
	return cr.repo.ListKeys(ctx)
}

func (cr *CachedRepository) UpdateKeyMetadata(ctx context.Context, id domain.KeyID, metadata *pk.KeyMetadata) error {
	err := cr.repo.UpdateKeyMetadata(ctx, id, metadata)
	if err == nil {
		cr.invalidateCache(id)
	}
	return err
}

func (cr *CachedRepository) RotateKey(ctx context.Context, id domain.KeyID, newEncryptedDEK []byte) (*domain.Key, error) {
	rotatedKey, err := cr.repo.RotateKey(ctx, id, newEncryptedDEK)
	if err == nil {
		cr.invalidateCache(id)
	}
	return rotatedKey, err
}

func (cr *CachedRepository) RevokeKey(ctx context.Context, id domain.KeyID) error {
	err := cr.repo.RevokeKey(ctx, id)
	if err == nil {
		cr.invalidateCache(id)
	}
	return err
}

func (cr *CachedRepository) GetKeyVersions(ctx context.Context, id domain.KeyID) ([]*domain.Key, error) {
	// Bypassing cache for simplicity.
	return cr.repo.GetKeyVersions(ctx, id)
}

func (cr *CachedRepository) Exists(ctx context.Context, id domain.KeyID) (bool, error) {
	cacheKey := cr.getCacheKey(id, 0)
	if _, found := cr.cache.Get(ctx, cacheKey); found {
		return true, nil
	}
	return cr.repo.Exists(ctx, id)
}

// Helper methods

func (cr *CachedRepository) getCacheKey(id domain.KeyID, version int32) string {
	sb := cr.optimizer.GetBuilder()
	defer cr.optimizer.PutBuilder(sb)

	sb.WriteString(id.String())
	if version == 0 {
		sb.WriteString(":latest")
	} else {
		sb.WriteString(":v")
		sb.WriteString(strconv.Itoa(int(version)))
	}
	return sb.String()
}

func (cr *CachedRepository) storeInCache(cacheKey string, k *domain.Key) {
	cr.cache.Set(context.Background(), cacheKey, k, 0)

	cr.cacheIndexMux.Lock()
	keyIDStr := k.ID.String()
	if _, ok := cr.cacheIndex[keyIDStr]; !ok {
		cr.cacheIndex[keyIDStr] = make(map[string]struct{})
	}
	cr.cacheIndex[keyIDStr][cacheKey] = struct{}{}
	cr.cacheIndexMux.Unlock()
}

func (cr *CachedRepository) invalidateCache(id domain.KeyID) {
	cr.cacheIndexMux.RLock()
	keyIDStr := id.String()
	keysToDel := make(map[string]struct{})
	if keys, ok := cr.cacheIndex[keyIDStr]; ok {
		for k := range keys {
			keysToDel[k] = struct{}{}
		}
	}
	cr.cacheIndexMux.RUnlock()

	for cacheKey := range keysToDel {
		cr.cache.Delete(context.Background(), cacheKey)
	}
}package persistence

import (
	"context"
	"crypto/tls"
	"fmt"
	"time"
	"github.com/jackc/pgx/v5/pgxpool"
	"github.com/spounge-ai/polykey/internal/infra/config"
)

// NewSecureConnectionPool creates a new database connection pool with enhanced security settings.
func NewSecureConnectionPool(ctx context.Context, dbConfig config.NeonDBConfig, serverConfig config.ServerConfig, persistenceConfig config.PersistenceConfig) (*pgxpool.Pool, error) {
	poolConfig, err := pgxpool.ParseConfig(dbConfig.URL)
	if err != nil {
		return nil, fmt.Errorf("failed to parse db config: %w", err)
	}

	// Apply secure settings from a new SecureConnectionConfig struct if it were defined
	// For now, we will use the existing config structs to apply some settings.
	if serverConfig.Mode == "production" && !persistenceConfig.Database.TLS.Enabled {
		return nil, fmt.Errorf("database connection must use TLS in production mode")
	}

	if persistenceConfig.Database.TLS.Enabled {
		poolConfig.ConnConfig.TLSConfig = &tls.Config{
			ServerName:         poolConfig.ConnConfig.Host,
			InsecureSkipVerify: false, // Always false in production
			MinVersion:         tls.VersionTLS12,
		}
	}

	poolConfig.MaxConns = persistenceConfig.Database.Connection.MaxConns
	poolConfig.MinConns = persistenceConfig.Database.Connection.MinConns
	poolConfig.MaxConnIdleTime = 30 * time.Second
	poolConfig.MaxConnLifetime = 5 * time.Minute
	poolConfig.HealthCheckPeriod = persistenceConfig.Database.Connection.HealthCheckPeriod

	pool, err := pgxpool.NewWithConfig(ctx, poolConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to create connection pool: %w", err)
	}

	if err := pool.Ping(ctx); err != nil {
		pool.Close()
		return nil, fmt.Errorf("failed to ping database: %w", err)
	}

	return pool, nil
}
package persistence

import (
	"context"
	"sync"
	"time"

	"github.com/jackc/pgx/v5/pgxpool"
)

type AlertLevel int

const (
	AlertLevelInfo AlertLevel = iota
	AlertLevelWarning
	AlertLevelCritical
)

// AlerterInterface defines a simple interface for sending alerts.
type AlerterInterface interface {
	SendAlert(level AlertLevel, message string, err error)
}

type ConnectionMonitor struct {
	pool      *pgxpool.Pool
	alerter   AlerterInterface
	mu        sync.RWMutex
	isHealthy bool
}

func NewConnectionMonitor(pool *pgxpool.Pool, alerter AlerterInterface) *ConnectionMonitor {
	return &ConnectionMonitor{
		pool:      pool,
		alerter:   alerter,
		isHealthy: true, // Assume healthy on startup
	}
}

func (cm *ConnectionMonitor) Start(ctx context.Context, interval time.Duration) {
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			cm.performHealthCheck(ctx)
		}
	}
}

func (cm *ConnectionMonitor) performHealthCheck(ctx context.Context) {
	checkCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	err := cm.pool.Ping(checkCtx)

	cm.mu.Lock()
	defer cm.mu.Unlock()

	if err != nil {
		if cm.isHealthy {
			cm.isHealthy = false
			if cm.alerter != nil {
				cm.alerter.SendAlert(AlertLevelCritical, "Database connection unhealthy", err)
			}
		}
	} else {
		if !cm.isHealthy {
			cm.isHealthy = true
			if cm.alerter != nil {
				cm.alerter.SendAlert(AlertLevelInfo, "Database connection recovered", nil)
			}
		}
	}
}

func (cm *ConnectionMonitor) IsHealthy() bool {
	cm.mu.RLock()
	defer cm.mu.RUnlock()
	return cm.isHealthy
}
package persistence

import (
	"context"
	"time"

	"github.com/spounge-ai/polykey/internal/domain"
	"github.com/spounge-ai/polykey/pkg/patterns/circuitbreaker"
	pk "github.com/spounge-ai/spounge-proto/gen/go/polykey/v2"
)

// KeyRepositoryCircuitBreaker adds a circuit breaker to a KeyRepository.
// It uses multiple type-safe breakers to avoid runtime type assertions.
type KeyRepositoryCircuitBreaker struct {
	repo            domain.KeyRepository
	getKeyBreaker   *circuitbreaker.Breaker[*domain.Key]
	listKeysBreaker *circuitbreaker.Breaker[[]*domain.Key]
	existsBreaker   *circuitbreaker.Breaker[bool]
	voidBreaker     *circuitbreaker.Breaker[any] // For methods returning only an error
}

// NewKeyRepositoryCircuitBreaker creates a new KeyRepository with a circuit breaker.
func NewKeyRepositoryCircuitBreaker(repo domain.KeyRepository, maxFailures int, resetTimeout time.Duration) domain.KeyRepository {
	// Shared options for all breakers
	opts := []circuitbreaker.Option[any]{
		circuitbreaker.WithResetTimeout[any](resetTimeout),
	}

	// It's safe to cast options for different generic types if they don't depend on the type T.
	// This is a bit of a workaround for Go's type system regarding generic functional options.
	getKeyOpts := []circuitbreaker.Option[*domain.Key]{
		circuitbreaker.WithResetTimeout[*domain.Key](resetTimeout),
	}
	listKeysOpts := []circuitbreaker.Option[[]*domain.Key]{
		circuitbreaker.WithResetTimeout[[]*domain.Key](resetTimeout),
	}
	existsOpts := []circuitbreaker.Option[bool]{
		circuitbreaker.WithResetTimeout[bool](resetTimeout),
	}

	return &KeyRepositoryCircuitBreaker{
		repo:            repo,
		getKeyBreaker:   circuitbreaker.New(maxFailures, getKeyOpts...),
		listKeysBreaker: circuitbreaker.New(maxFailures, listKeysOpts...),
		existsBreaker:   circuitbreaker.New(maxFailures, existsOpts...),
		voidBreaker:     circuitbreaker.New(maxFailures, opts...),
	}
}

func (cb *KeyRepositoryCircuitBreaker) GetKey(ctx context.Context, id domain.KeyID) (*domain.Key, error) {
	return cb.getKeyBreaker.Execute(ctx, func(ctx context.Context) (*domain.Key, error) {
		return cb.repo.GetKey(ctx, id)
	})
}

func (cb *KeyRepositoryCircuitBreaker) GetKeyByVersion(ctx context.Context, id domain.KeyID, version int32) (*domain.Key, error) {
	return cb.getKeyBreaker.Execute(ctx, func(ctx context.Context) (*domain.Key, error) {
		return cb.repo.GetKeyByVersion(ctx, id, version)
	})
}

func (cb *KeyRepositoryCircuitBreaker) CreateKey(ctx context.Context, key *domain.Key) error {
	_, err := cb.voidBreaker.Execute(ctx, func(ctx context.Context) (any, error) {
		return nil, cb.repo.CreateKey(ctx, key)
	})
	return err
}

func (cb *KeyRepositoryCircuitBreaker) CreateKeys(ctx context.Context, keys []*domain.Key) error {
	_, err := cb.voidBreaker.Execute(ctx, func(ctx context.Context) (any, error) {
		return nil, cb.repo.CreateKeys(ctx, keys)
	})
	return err
}

func (cb *KeyRepositoryCircuitBreaker) ListKeys(ctx context.Context) ([]*domain.Key, error) {
	return cb.listKeysBreaker.Execute(ctx, func(ctx context.Context) ([]*domain.Key, error) {
		return cb.repo.ListKeys(ctx)
	})
}

func (cb *KeyRepositoryCircuitBreaker) UpdateKeyMetadata(ctx context.Context, id domain.KeyID, metadata *pk.KeyMetadata) error {
	_, err := cb.voidBreaker.Execute(ctx, func(ctx context.Context) (any, error) {
		return nil, cb.repo.UpdateKeyMetadata(ctx, id, metadata)
	})
	return err
}

func (cb *KeyRepositoryCircuitBreaker) RotateKey(ctx context.Context, id domain.KeyID, newEncryptedDEK []byte) (*domain.Key, error) {
	return cb.getKeyBreaker.Execute(ctx, func(ctx context.Context) (*domain.Key, error) {
		return cb.repo.RotateKey(ctx, id, newEncryptedDEK)
	})
}

func (cb *KeyRepositoryCircuitBreaker) RevokeKey(ctx context.Context, id domain.KeyID) error {
	_, err := cb.voidBreaker.Execute(ctx, func(ctx context.Context) (any, error) {
		return nil, cb.repo.RevokeKey(ctx, id)
	})
	return err
}

func (cb *KeyRepositoryCircuitBreaker) GetKeyVersions(ctx context.Context, id domain.KeyID) ([]*domain.Key, error) {
	return cb.listKeysBreaker.Execute(ctx, func(ctx context.Context) ([]*domain.Key, error) {
		return cb.repo.GetKeyVersions(ctx, id)
	})
}

func (cb *KeyRepositoryCircuitBreaker) Exists(ctx context.Context, id domain.KeyID) (bool, error) {
	return cb.existsBreaker.Execute(ctx, func(ctx context.Context) (bool, error) {
		return cb.repo.Exists(ctx, id)
	})
}
package persistence

import (
	"hash/fnv"
	"log/slog"

	"github.com/jackc/pgx/v5/pgxpool"
	"github.com/spounge-ai/polykey/internal/domain"
	"github.com/spounge-ai/polykey/pkg/postgres"
)

// PostgresBase provides a base implementation for PostgreSQL-backed repositories.
// It centralizes connection management, prepared statements, and other common logic.
type PostgresBase struct {
	*postgres.Client
	logger *slog.Logger
}

// NewPostgresBase creates a new PostgresBase.
func NewPostgresBase(db *pgxpool.Pool, logger *slog.Logger) *PostgresBase {
	return &PostgresBase{
		Client: postgres.NewClient(db),
		logger: logger,
	}
}

// GetLockID generates a unique int64 lock ID from a KeyID for use with advisory locks.
func (c *PostgresBase) GetLockID(id domain.KeyID) int64 {
	h := fnv.New64a()
	h.Write([]byte(id.String()))
	return int64(h.Sum64())
}package persistence

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"log/slog"
	"time"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgxpool"
	consts "github.com/spounge-ai/polykey/internal/constants"
	"github.com/spounge-ai/polykey/internal/domain"
	app_errors "github.com/spounge-ai/polykey/internal/errors"
	psql "github.com/spounge-ai/polykey/pkg/postgres"
	pk "github.com/spounge-ai/spounge-proto/gen/go/polykey/v2"
	"google.golang.org/protobuf/types/known/timestamppb"
)

const (
	defaultKeysCapacity = 100
	versionsCapacity    = 10
)

type PSQLAdapter struct {
	*PostgresBase
	optimizer *QueryOptimizer
	txManager *TransactionManager[*domain.Key]
}

func NewPSQLAdapter(db *pgxpool.Pool, logger *slog.Logger) (*PSQLAdapter, error) {
	a := &PSQLAdapter{
		PostgresBase: NewPostgresBase(db, logger),
		optimizer:    NewQueryOptimizer(),
		txManager:    NewTransactionManager[*domain.Key](logger),
	}

	if err := a.PrepareStatements(context.Background(), consts.Queries); err != nil {
		return nil, fmt.Errorf("failed to prepare statements: %w", err)
	}

	return a, nil
}

func (a *PSQLAdapter) GetKey(ctx context.Context, id domain.KeyID) (*domain.Key, error) {
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	row := a.DB.QueryRow(ctx, consts.StmtGetLatestKey, id.String())
	key, err := ScanKeyRow(row)
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, psql.ErrKeyNotFound
		}
		return nil, fmt.Errorf("failed to get key %s: %w", id.String(), err)
	}

	key.ID = id
	return key, nil
}

func (a *PSQLAdapter) GetKeyByVersion(ctx context.Context, id domain.KeyID, version int32) (*domain.Key, error) {
	if version <= 0 {
		return nil, psql.ErrInvalidVersion
	}
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	row := a.DB.QueryRow(ctx, consts.StmtGetKeyByVersion, id.String(), version)
	key, err := ScanKeyRow(row)
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, psql.ErrKeyNotFound
		}
		return nil, fmt.Errorf("failed to get key %s version %d: %w", id.String(), version, err)
	}

	key.ID = id
	key.Version = version
	return key, nil
}

func (a *PSQLAdapter) CreateKey(ctx context.Context, key *domain.Key) error {
	if key == nil {
		return errors.New("key cannot be nil")
	}
	if key.Metadata == nil {
		return errors.New("key metadata cannot be nil")
	}
	if len(key.EncryptedDEK) == 0 {
		return errors.New("encrypted DEK cannot be empty")
	}

	exists, err := a.Exists(ctx, key.ID)
	if err != nil {
		return fmt.Errorf("failed to check key existence: %w", err)
	}
	if exists {
		return psql.ErrKeyAlreadyExists
	}

	metadataRaw, err := a.optimizer.MarshalWithBuffer(key.Metadata)
	if err != nil {
		return fmt.Errorf("failed to marshal metadata: %w", err)
	}

	storageType := getStorageTypeOptimized(key.Metadata.GetStorageType())

	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	_, err = a.DB.Exec(ctx, consts.StmtCreateKey,
		key.ID.String(), key.Version, metadataRaw, key.EncryptedDEK,
		key.Status, storageType, key.CreatedAt, key.UpdatedAt)

	if err != nil {
		return fmt.Errorf("failed to create key %s: %w", key.ID.String(), err)
	}

	return nil
}

func (a *PSQLAdapter) CreateKeys(ctx context.Context, keys []*domain.Key) error {
	batch := &pgx.Batch{}
	for _, key := range keys {
		metadataRaw, err := a.optimizer.MarshalWithBuffer(key.Metadata)
		if err != nil {
			return fmt.Errorf("failed to marshal metadata for key %s: %w", key.ID.String(), err)
		}
		storageType := getStorageTypeOptimized(key.Metadata.GetStorageType())
		batch.Queue(consts.StmtCreateKey, key.ID.String(), key.Version, metadataRaw, key.EncryptedDEK, key.Status, storageType, key.CreatedAt, key.UpdatedAt)
	}

	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	br := a.DB.SendBatch(ctx, batch)
	defer func() {
		if err := br.Close(); err != nil {
			a.logger.Error("failed to close batch", "error", err)
		}
	}()

	for i := 0; i < len(keys); i++ {
		_, err := br.Exec()
		if err != nil {
			return fmt.Errorf("failed to create key in batch: %w", err)
		}
	}

	return nil
}

func (a *PSQLAdapter) ListKeys(ctx context.Context) ([]*domain.Key, error) {
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	rows, err := a.DB.Query(ctx, consts.StmtListKeys)
	if err != nil {
		return nil, fmt.Errorf("failed to query keys: %w", err)
	}
	defer rows.Close()

	keys := make([]*domain.Key, 0, defaultKeysCapacity)
	for rows.Next() {
		key, err := ScanKeyRowWithID(rows)
		if err != nil {
			a.logger.Error("failed to scan key row in ListKeys", "error", err)
			continue
		}
		keys = append(keys, key)
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("error iterating over rows: %w", err)
	}

	return keys, nil
}

func (a *PSQLAdapter) UpdateKeyMetadata(ctx context.Context, id domain.KeyID, metadata *pk.KeyMetadata) error {
	if metadata == nil {
		return errors.New("metadata cannot be nil")
	}

	metadataRaw, err := a.optimizer.MarshalWithBuffer(metadata)
	if err != nil {
		return fmt.Errorf("failed to marshal metadata: %w", err)
	}

	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	result, err := a.DB.Exec(ctx, consts.StmtUpdateMetadata, metadataRaw, time.Now(), id.String())
	if err != nil {
		return fmt.Errorf("failed to update key metadata %s: %w", id.String(), err)
	}

	if result.RowsAffected() == 0 {
		return psql.ErrKeyNotFound
	}

	return nil
}

func (a *PSQLAdapter) RotateKey(ctx context.Context, id domain.KeyID, newEncryptedDEK []byte) (*domain.Key, error) {
	if len(newEncryptedDEK) == 0 {
		return nil, errors.New("new encrypted DEK cannot be empty")
	}

	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	return a.txManager.ExecuteInTransaction(ctx, a.DB, func(ctx context.Context, tx pgx.Tx) (*domain.Key, error) {
		return a.rotateKeyInTx(ctx, tx, id, newEncryptedDEK)
	})
}

func (a *PSQLAdapter) rotateKeyInTx(ctx context.Context, tx pgx.Tx, id domain.KeyID, newEncryptedDEK []byte) (*domain.Key, error) {
	lockID := a.GetLockID(id)
	locked, err := a.TryAcquireLock(ctx, tx, lockID)
	if err != nil {
		return nil, err
	}
	if !locked {
		return nil, app_errors.ErrKeyRotationLocked
	}

	const selectQuery = `SELECT version, metadata, storage_type FROM keys 
	                     WHERE id = $1::uuid ORDER BY version DESC LIMIT 1 FOR UPDATE`
	
	var currentVersion int32
	var metadataRaw []byte
	var storageType string

	err = tx.QueryRow(ctx, selectQuery, id.String()).Scan(&currentVersion, &metadataRaw, &storageType)
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, psql.ErrKeyNotFound
		}
		return nil, fmt.Errorf("failed to get current key version: %w", err)
	}

	const updateQuery = `UPDATE keys SET status = $1 WHERE id = $2::uuid AND version = $3`
	_, err = tx.Exec(ctx, updateQuery, domain.KeyStatusRotated, id.String(), currentVersion)
	if err != nil {
		return nil, fmt.Errorf("failed to update old key version status: %w", err)
	}

	var metadata pk.KeyMetadata
	if err := json.Unmarshal(metadataRaw, &metadata); err != nil {
		return nil, fmt.Errorf("failed to unmarshal metadata: %w", err)
	}

	newVersion := currentVersion + 1
	now := time.Now()
	metadata.Version = newVersion
	metadata.UpdatedAt = timestamppb.New(now)

	newMetadataRaw, err := a.optimizer.MarshalWithBuffer(&metadata)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal updated metadata: %w", err)
	}

	const insertQuery = `INSERT INTO keys (id, version, metadata, encrypted_dek, status, storage_type, created_at, updated_at) 
	                     VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`

	_, err = tx.Exec(ctx, insertQuery,
		id.String(), newVersion, newMetadataRaw, newEncryptedDEK,
		domain.KeyStatusActive, storageType, now, now)
	if err != nil {
		return nil, fmt.Errorf("failed to insert new key version: %w", err)
	}

	return &domain.Key{
		ID:           id,
		Version:      newVersion,
		Metadata:     &metadata,
		EncryptedDEK: newEncryptedDEK,
		Status:       domain.KeyStatusActive,
		CreatedAt:    now,
		UpdatedAt:    now,
	}, nil
}

func (a *PSQLAdapter) RevokeKey(ctx context.Context, id domain.KeyID) error {
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	result, err := a.DB.Exec(ctx, consts.StmtRevokeKey, domain.KeyStatusRevoked, time.Now(), id.String())
	if err != nil {
		return fmt.Errorf("failed to revoke key %s: %w", id.String(), err)
	}

	if result.RowsAffected() == 0 {
		return psql.ErrKeyNotFound
	}

	return nil
}

func (a *PSQLAdapter) GetKeyVersions(ctx context.Context, id domain.KeyID) ([]*domain.Key, error) {
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	rows, err := a.DB.Query(ctx, consts.StmtGetVersions, id.String())
	if err != nil {
		return nil, fmt.Errorf("failed to query key versions: %w", err)
	}
	defer rows.Close()

	keys := make([]*domain.Key, 0, versionsCapacity)
	for rows.Next() {
		key, err := ScanKeyRow(rows)
		if err != nil {
			a.logger.Error("failed to scan key row in GetKeyVersions", "error", err)
			continue
		}
		key.ID = id
		keys = append(keys, key)
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("error iterating over key versions: %w", err)
	}

	return keys, nil
}

func (a *PSQLAdapter) Exists(ctx context.Context, id domain.KeyID) (bool, error) {
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	var exists bool
	err := a.DB.QueryRow(ctx, consts.StmtCheckExists, id.String()).Scan(&exists)
	if err != nil {
		return false, fmt.Errorf("failed to check key existence %s: %w", id.String(), err)
	}

	return exists, nil
}

func (a *PSQLAdapter) Close() error {
	a.DB.Close()
	return nil
}

package persistence

import (
	"encoding/json"
	"strings"
	"sync"
)

const (
	// builderInitialCap is the initial capacity for the string builder.
	builderInitialCap = 64
)

// QueryOptimizer manages performance optimizations like buffer and builder pools.
type QueryOptimizer struct {
	queryBuilderPool *sync.Pool
	bufferPool       *BufferPool
}

// BufferPool manages pools of byte slices for sensitive data.
type BufferPool struct {
	metaBuffer []byte
	bufferMux  sync.Mutex
}

// NewQueryOptimizer creates a new QueryOptimizer.
func NewQueryOptimizer() *QueryOptimizer {
	return &QueryOptimizer{
		queryBuilderPool: &sync.Pool{
			New: func() interface{} {
				sb := &strings.Builder{}
				sb.Grow(builderInitialCap)
				return sb
			},
		},
		bufferPool: &BufferPool{
			metaBuffer: make([]byte, 0, 512),
		},
	}
}

// GetBuilder retrieves a strings.Builder from the pool.
func (qo *QueryOptimizer) GetBuilder() *strings.Builder {
	return qo.queryBuilderPool.Get().(*strings.Builder)
}

// PutBuilder returns a strings.Builder to the pool.
func (qo *QueryOptimizer) PutBuilder(sb *strings.Builder) {
	sb.Reset()
	qo.queryBuilderPool.Put(sb)
}

// MarshalWithBuffer uses buffer pool to reduce allocations for JSON marshaling.
func (qo *QueryOptimizer) MarshalWithBuffer(v interface{}) ([]byte, error) {
	qo.bufferPool.bufferMux.Lock()
	defer qo.bufferPool.bufferMux.Unlock()

	qo.bufferPool.metaBuffer = qo.bufferPool.metaBuffer[:0] // Reset buffer
	data, err := json.Marshal(v)
	if err != nil {
		return nil, err
	}

	// It's important to copy the data to a new slice before returning it,
	// as the buffer will be reused.
	result := make([]byte, len(data))
	copy(result, data)
	return result, nil
}package persistence

import (
	"bytes"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"log/slog"
	"sort"
	"strings"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/aws/aws-sdk-go-v2/service/s3/types"
	"github.com/spounge-ai/polykey/internal/domain"
	pk "github.com/spounge-ai/spounge-proto/gen/go/polykey/v2"
)

type S3Storage struct {
	client     *s3.Client
	bucketName string
	logger     *slog.Logger
}

func NewS3Storage(cfg aws.Config, bucketName string, logger *slog.Logger) (*S3Storage, error) {
	s3Client := s3.NewFromConfig(cfg)
	return &S3Storage{
		client:     s3Client,
		bucketName: bucketName,
		logger:     logger,
	}, nil
}

type s3KeyObject struct {
	ID            string          `json:"id"`
	EncryptedDEK  []byte          `json:"encrypted_dek"`
	Metadata      *pk.KeyMetadata `json:"metadata"`
	Version       int32           `json:"version"`
	Status        pk.KeyStatus    `json:"status"`
	CreatedAt     int64           `json:"created_at"`
	UpdatedAt     int64           `json:"updated_at"`
}

func (s *S3Storage) GetKey(ctx context.Context, id domain.KeyID) (*domain.Key, error) {
	keyPath := fmt.Sprintf("keys/%s/latest.json", id.String())
	return s.getKeyFromPath(ctx, keyPath)
}

func (s *S3Storage) GetKeyByVersion(ctx context.Context, id domain.KeyID, version int32) (*domain.Key, error) {
	keyPath := fmt.Sprintf("keys/%s/v%d.json", id.String(), version)
	return s.getKeyFromPath(ctx, keyPath)
}

func (s *S3Storage) CreateKey(ctx context.Context, key *domain.Key) error {
	return s.putKey(ctx, key)
}

func (s *S3Storage) CreateKeys(ctx context.Context, keys []*domain.Key) error {
	for _, key := range keys {
		if err := s.putKey(ctx, key); err != nil {
			return err
		}
	}
	return nil
}

func (s *S3Storage) getKeyFromPath(ctx context.Context, path string) (*domain.Key, error) {
	output, err := s.client.GetObject(ctx, &s3.GetObjectInput{
		Bucket: &s.bucketName,
		Key:    &path,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to get key object from S3: %w", err)
	}
	defer func() {
		if err := output.Body.Close(); err != nil {
			s.logger.Error("failed to close S3 object body", "error", err)
		}
	}()

	var keyObj s3KeyObject
	if err := json.NewDecoder(output.Body).Decode(&keyObj); err != nil {
		return nil, fmt.Errorf("failed to decode key object from S3: %w", err)
	}

	id, err := domain.KeyIDFromString(keyObj.ID)
	if err != nil {
		return nil, err
	}

	return &domain.Key{
		ID:           id,
		EncryptedDEK: keyObj.EncryptedDEK,
		Metadata:     keyObj.Metadata,
		Version:      keyObj.Version,
		Status:       domain.KeyStatus(pk.KeyStatus_name[int32(keyObj.Status)]),
		CreatedAt:    time.Unix(keyObj.CreatedAt, 0),
		UpdatedAt:    time.Unix(keyObj.UpdatedAt, 0),
	}, nil
}

func (s *S3Storage) putKey(ctx context.Context, key *domain.Key) error {
	keyObj := s3KeyObject{
		ID:           key.ID.String(),
		EncryptedDEK: key.EncryptedDEK,
		Metadata:     key.Metadata,
		Version:      key.Version,
		Status:       pk.KeyStatus(pk.KeyStatus_value[string(key.Status)]),
		CreatedAt:    key.CreatedAt.Unix(),
		UpdatedAt:    key.UpdatedAt.Unix(),
	}

	data, err := json.Marshal(keyObj)
	if err != nil {
		return fmt.Errorf("failed to marshal key object: %w", err)
	}

	versionPath := fmt.Sprintf("keys/%s/v%d.json", key.ID.String(), key.Version)
	_, err = s.client.PutObject(ctx, &s3.PutObjectInput{
		Bucket: &s.bucketName,
		Key:    &versionPath,
		Body:   bytes.NewReader(data),
	})
	if err != nil {
		return fmt.Errorf("failed to put versioned key object to S3: %w", err)
	}

	latestPath := fmt.Sprintf("keys/%s/latest.json", key.ID.String())
	_, err = s.client.PutObject(ctx, &s3.PutObjectInput{
		Bucket: &s.bucketName,
		Key:    &latestPath,
		Body:   bytes.NewReader(data),
	})
	if err != nil {
		if _, delErr := s.client.DeleteObject(ctx, &s3.DeleteObjectInput{Bucket: &s.bucketName, Key: &versionPath}); delErr != nil {
			s.logger.Error("failed to roll back S3 object", "path", versionPath, "error", delErr)
		}
		return fmt.Errorf("failed to put latest key object to S3: %w", err)
	}

	return nil
}

func (s *S3Storage) ListKeys(ctx context.Context) ([]*domain.Key, error) {
	prefix := "keys/"
	input := &s3.ListObjectsV2Input{
		Bucket:    &s.bucketName,
		Prefix:    &prefix,
		Delimiter: aws.String("/"),
	}

	var keys []*domain.Key
	paginator := s3.NewListObjectsV2Paginator(s.client, input)
	for paginator.HasMorePages() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to list objects from S3: %w", err)
		}

		for _, obj := range page.CommonPrefixes {
			keyIDStr := strings.TrimSuffix(strings.TrimPrefix(*obj.Prefix, prefix), "/")
			keyID, err := domain.KeyIDFromString(keyIDStr)
			if err != nil {
				s.logger.Error("failed to parse key id while listing", "keyID", keyIDStr, "error", err)
				continue
			}
			key, err := s.GetKey(ctx, keyID)
			if err != nil {
				s.logger.Error("failed to get key while listing", "keyID", keyID, "error", err)
				continue
			}
			keys = append(keys, key)
		}
	}

	return keys, nil
}

func (s *S3Storage) UpdateKeyMetadata(ctx context.Context, id domain.KeyID, metadata *pk.KeyMetadata) error {
	latestKey, err := s.GetKey(ctx, id)
	if err != nil {
		return fmt.Errorf("failed to get key for update: %w", err)
	}

	latestKey.Metadata = metadata
	latestKey.UpdatedAt = time.Now()

	return s.putKey(ctx, latestKey)
}

func (s *S3Storage) RotateKey(ctx context.Context, id domain.KeyID, newEncryptedDEK []byte) (*domain.Key, error) {
	latestKey, err := s.GetKey(ctx, id)
	if err != nil {
		return nil, fmt.Errorf("failed to get key for rotation: %w", err)
	}

	newVersion := latestKey.Version + 1
	now := time.Now()

	rotatedKey := &domain.Key{
		ID:           id,
		EncryptedDEK: newEncryptedDEK,
		Metadata:     latestKey.Metadata,
		Version:      newVersion,
		Status:       domain.KeyStatusActive,
		CreatedAt:    now,
		UpdatedAt:    now,
	}

	if err := s.putKey(ctx, rotatedKey); err != nil {
		return nil, fmt.Errorf("failed to create new key version during rotation: %w", err)
	}

	return rotatedKey, nil
}

func (s *S3Storage) RevokeKey(ctx context.Context, id domain.KeyID) error {
	latestKey, err := s.GetKey(ctx, id)
	if err != nil {
		return fmt.Errorf("failed to get key for revocation: %w", err)
	}

	latestKey.Status = domain.KeyStatusRevoked
	latestKey.UpdatedAt = time.Now()

	return s.putKey(ctx, latestKey)
}

func (s *S3Storage) GetKeyVersions(ctx context.Context, id domain.KeyID) ([]*domain.Key, error) {
	prefix := fmt.Sprintf("keys/%s/v", id.String())
	input := &s3.ListObjectsV2Input{
		Bucket: &s.bucketName,
		Prefix: &prefix,
	}

	var versions []*domain.Key
	paginator := s3.NewListObjectsV2Paginator(s.client, input)
	for paginator.HasMorePages() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to list objects from S3 for versions: %w", err)
		}

		for _, obj := range page.Contents {
			key, err := s.getKeyFromPath(ctx, *obj.Key)
			if err != nil {
				s.logger.Error("failed to get key version from path", "path", *obj.Key, "error", err)
				continue
			}
			versions = append(versions, key)
		}
	}

	sort.Slice(versions, func(i, j int) bool {
		return versions[i].Version > versions[j].Version
	})

	return versions, nil
}

func (s *S3Storage) Exists(ctx context.Context, id domain.KeyID) (bool, error) {
	keyPath := fmt.Sprintf("keys/%s/latest.json", id.String())
	_, err := s.client.HeadObject(ctx, &s3.HeadObjectInput{
		Bucket: &s.bucketName,
		Key:    &keyPath,
	})
	if err != nil {
		var nsk *types.NoSuchKey
		if errors.As(err, &nsk) {
			return false, nil
		}
		return false, err
	}
	return true, nil
}

func (s *S3Storage) HealthCheck() error {
	_, err := s.client.HeadBucket(context.Background(), &s3.HeadBucketInput{
		Bucket: &s.bucketName,
	})
	if err != nil {
		s.logger.Error("S3 health check failed", "error", err)
		return fmt.Errorf("S3 health check failed: %w", err)
	}
	return nil
}
package persistence

import (
	"encoding/json"
	"fmt"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5"
	"github.com/spounge-ai/polykey/internal/domain"
)

// ScanKeyRow scans a single row from a pgx.Row and returns a domain.Key, excluding the ID.
// This is used for queries where the ID is already known.
func ScanKeyRow(row pgx.Row) (*domain.Key, error) {
	var key domain.Key
	var metadataRaw []byte
	var storageType string

	err := row.Scan(
		&key.Version,
		&metadataRaw,
		&key.EncryptedDEK,
		&key.Status,
		&storageType,
		&key.CreatedAt,
		&key.UpdatedAt,
		&key.RevokedAt,
	)
	if err != nil {
		return nil, fmt.Errorf("failed to scan key row: %w", err)
	}

	if err := json.Unmarshal(metadataRaw, &key.Metadata); err != nil {
		return nil, fmt.Errorf("failed to unmarshal metadata: %w", err)
	}

	return &key, nil
}

// ScanKeyRowWithID scans a single row from a pgx.Row and returns a domain.Key, including the ID.
// This is used for queries like ListKeys where the ID is part of the result set.
func ScanKeyRowWithID(row pgx.Row) (*domain.Key, error) {
	var key domain.Key
	var id uuid.UUID
	var metadataRaw []byte
	var storageType string

	err := row.Scan(
		&id,
		&key.Version,
		&metadataRaw,
		&key.EncryptedDEK,
		&key.Status,
		&storageType,
		&key.CreatedAt,
		&key.UpdatedAt,
		&key.RevokedAt,
	)
	if err != nil {
		return nil, fmt.Errorf("failed to scan key row: %w", err)
	}

	key.ID, err = domain.KeyIDFromString(id.String())
	if err != nil {
		return nil, fmt.Errorf("failed to create key id from uuid string: %w", err)
	}

	if err := json.Unmarshal(metadataRaw, &key.Metadata); err != nil {
		return nil, fmt.Errorf("failed to unmarshal metadata for key %s: %w", key.ID.String(), err)
	}

	return &key, nil
}
package persistence

import (
	consts "github.com/spounge-ai/polykey/internal/constants"
	pk "github.com/spounge-ai/spounge-proto/gen/go/polykey/v2"
)

// Pre-compiled storage type mappings for better performance
var storageTypeMap = map[pk.StorageProfile]string{
	pk.StorageProfile_STORAGE_PROFILE_STANDARD: consts.StorageTypeStandard,
	pk.StorageProfile_STORAGE_PROFILE_HARDENED: consts.StorageTypeHardened,
}

// getStorageTypeOptimized uses pre-compiled map for better performance
func getStorageTypeOptimized(storageProfile pk.StorageProfile) string {
	if storageType, ok := storageTypeMap[storageProfile]; ok {
		return storageType
	}
	return consts.StorageTypeUnknown
}
package persistence

import (
	"context"
	"errors"
	"fmt"
	"log/slog"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgxpool"
	
)

// TransactionManager provides a generic way to execute functions within a database transaction.
type TransactionManager[T any] struct {
	logger *slog.Logger
}

// NewTransactionManager creates a new TransactionManager.
func NewTransactionManager[T any](logger *slog.Logger) *TransactionManager[T] {
	return &TransactionManager[T]{logger: logger}
}

// ExecuteInTransaction executes the given function within a transaction.
// It automatically handles begin, commit, and rollback.
func (tm *TransactionManager[T]) ExecuteInTransaction(
	ctx context.Context,
	db *pgxpool.Pool,
	fn func(context.Context, pgx.Tx) (T, error),
) (T, error) {
	var zero T
	tx, err := db.Begin(ctx)
	if err != nil {
		return zero, fmt.Errorf("failed to begin transaction: %w", err)
	}

	defer func() {
		if rErr := tx.Rollback(ctx); rErr != nil &&
			!errors.Is(rErr, context.Canceled) &&
			!errors.Is(rErr, pgx.ErrTxClosed) {
			tm.logger.Error("failed to rollback transaction", "error", rErr)
		}
	}()

	result, err := fn(ctx, tx)
	if err != nil {
		return zero, err
	}

	if err := tx.Commit(ctx); err != nil {
		return zero, fmt.Errorf("failed to commit transaction: %w", err)
	}

	return result, nil
}
